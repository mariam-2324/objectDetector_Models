{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **OBJECT DETECTION WITH DESCRIPTION:**üöÄ\n",
        "## **MODEL NAME:** moondream2 üåÖ"
      ],
      "metadata": {
        "id": "oYiWfMIJ0kiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loaded from Huggingface, This vision-language model (moondream2) generate a description for an image.* üñºÔ∏è"
      ],
      "metadata": {
        "id": "WgeDlQfHo5bz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1:üëâInstalling the transformers Library üì¶"
      ],
      "metadata": {
        "id": "JKzOlALapF8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "iAqEXTjP0z6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2:üëâImporting Required Libraries üìö\n",
        "\n",
        "*   PIL from Pillow Library; this library handles the image input"
      ],
      "metadata": {
        "id": "pW4otaXHpEhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "-uo3eX9I0iaC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3:üëâLoading the Model (First Instance) üß†\n",
        "* Loads the pre-trained moondream2 model from the Hugging Face model hub.\n",
        "* The model is identified by \"vikhyatk/moondream2\", a specific vision-language model designed to process images and text. üì∑\n",
        "* trust_remote_code=True allows the execution of custom code from the model‚Äôs repository, which may be required for non-standard models like moondream2. ‚ö†Ô∏è\n",
        "* torch_dtype=\"auto\" lets PyTorch automatically select the appropriate data type (e.g., float32 or float16) based on the hardware (CPU/GPU). ‚ö°"
      ],
      "metadata": {
        "id": "N0S03QESqvl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from PIL import Image\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"vikhyatk/moondream2\", trust_remote_code=True, torch_dtype=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vikhyatk/moondream2\")"
      ],
      "metadata": {
        "id": "ttyxDIsi5Yq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4:üëâLoading the Image üñºÔ∏è\n",
        "* Uses PIL to open an image file named tiger.jpg located at the path /content/tiger.jpg (common in Google Colab environments).\n",
        "* The image is loaded into memory as a PIL.Image object for processing by the model. üìÇ\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8wVrLqeCq1Zb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1ffb9fd",
        "outputId": "7ebc1447-58b7-4352-905e-84d16862e528"
      },
      "source": [
        "# Example usage: Load an image and generate a description\n",
        "image = Image.open(\"/content/tiger.jpg\") # Replace with your image path\n",
        "\n",
        "enc_image = model.encode_image(image)\n",
        "caption = model.answer_question(enc_image, \"Describe this image.\", tokenizer)\n",
        "print(caption)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A majestic tiger stands in the center of the frame, its body partially obscured by lush green foliage. The tiger's striking orange and black stripes contrast with the vibrant greenery surrounding it. The tiger's gaze is directed towards the camera, giving a clear view of its powerful features, including its large eyes, prominent nose, and fluffy tail. The tiger's fur appears to be thick and possibly wet. The background is blurred, suggesting the density of the vegetation and the tiger's solitary presence within it. There are no discernible texts or other objects in the image, and the relative position of the tiger to the foliage indicates it is positioned roughly in the center of the frame.\n"
          ]
        }
      ]
    }
  ]
}